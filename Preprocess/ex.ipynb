{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"new.csv\")\n",
    "\n",
    "\n",
    "df = df[df['crimeaditionalinfo'].notnull()]\n",
    "\n",
    "\n",
    "df['sub_category'] = df['sub_category'].fillna(df['category'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Unnamed: 0                               category  \\\n",
      "0                0  Online and Social Media Related Crime   \n",
      "1                1                 Online Financial Fraud   \n",
      "2                2               Online Gambling  Betting   \n",
      "3                3  Online and Social Media Related Crime   \n",
      "4                4                 Online Financial Fraud   \n",
      "...            ...                                    ...   \n",
      "124910      124910  Online and Social Media Related Crime   \n",
      "124911      124911                 Online Financial Fraud   \n",
      "124912      124912                  Any Other Cyber Crime   \n",
      "124913      124913                 Online Financial Fraud   \n",
      "124914      124914                  Any Other Cyber Crime   \n",
      "\n",
      "                             sub_category  \\\n",
      "0       Cyber Bullying  Stalking  Sexting   \n",
      "1                       Fraud CallVishing   \n",
      "2                Online Gambling  Betting   \n",
      "3                        Online Job Fraud   \n",
      "4                       Fraud CallVishing   \n",
      "...                                   ...   \n",
      "124910           Online Matrimonial Fraud   \n",
      "124911     Internet Banking Related Fraud   \n",
      "124912                              Other   \n",
      "124913     Internet Banking Related Fraud   \n",
      "124914                              Other   \n",
      "\n",
      "                                       crimeaditionalinfo  \n",
      "0       continue receive random call abusive message w...  \n",
      "1       fraudster continuously message ask pay money s...  \n",
      "2       act like police demand money add section text ...  \n",
      "3       apna job apply job interview telecalling resou...  \n",
      "4       receive call lady state send new phone vivo re...  \n",
      "...                                                   ...  \n",
      "124910  lady name rashmi probably fake name call day a...  \n",
      "124911  mr chokhe ram two pers mobile number find gool...  \n",
      "124912  mai bibekbraj maine pahle ki complain kar chuk...  \n",
      "124913  receive url link update kyc mobile open receiv...  \n",
      "124914  saw add facebook job placement want job contac...  \n",
      "\n",
      "[124887 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "# Initialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "# Step 1: Remove special characters\n",
    "def remove_special_characters(text):\n",
    "    return re.sub(r'[^A-Za-z0-9\\s]', '', text)\n",
    "\n",
    "# Step 2: Lowercase the entire column\n",
    "def lowercase_text(text):\n",
    "    return text.lower()\n",
    "\n",
    "# Step 3: Stop word removal\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = word_tokenize(text)\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Step 4: Lemmatization using POS tags\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    \"\"\"\n",
    "    Convert POS tag from treebank to wordnet format for lemmatization.\n",
    "    \"\"\"\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN  # Default to NOUN\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    words = word_tokenize(text)\n",
    "    pos_tags = pos_tag(words)  # POS tagging\n",
    "    lemmatized_words = []\n",
    "    \n",
    "    for word, tag in pos_tags:\n",
    "        wordnet_pos = get_wordnet_pos(tag)\n",
    "        lemmatized_word = lemmatizer.lemmatize(word, wordnet_pos)\n",
    "        lemmatized_words.append(lemmatized_word)\n",
    "    \n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "# Apply the functions to the crimeaditionalinfo column\n",
    "df['crimeaditionalinfo'] = df['crimeaditionalinfo'].apply(remove_special_characters)\n",
    "df['crimeaditionalinfo'] = df['crimeaditionalinfo'].apply(lowercase_text)\n",
    "df['crimeaditionalinfo'] = df['crimeaditionalinfo'].apply(remove_stopwords)\n",
    "df['crimeaditionalinfo'] = df['crimeaditionalinfo'].apply(lemmatize_text)\n",
    "\n",
    "# Show the processed data\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('final.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
